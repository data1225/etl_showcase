import json, os, time
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from typing import List, Optional, Dict, Union
from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound
from yt_dlp import YoutubeDL
from faster_whisper import WhisperModel

# local model
from etl_showcase.config.youtube import (
    YOUTUBE_API_KEY, 
    YOUTUBE_SPREADSHEET_ID, 
)
from etl_showcase.domain.models import (
    BaseResponse, 
    StatusCode,
    RegionCode, 
    LanguageCode
)
from etl_showcase.domain.youtube_models import (
    YoutubeVideo,
    YoutubeComment,
    VideoSearchOrder,
)
from etl_showcase.infrastructure.utils.time_utils import get_now_time_string

def get_youtube_service():
    return build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)

def youtube_search_videos(
    query: str,                                           # æœå°‹é—œéµè©
    search_count: int = 5,                                # æ¬²æ’ˆå–å½±ç‰‡ç¸½ç­†æ•¸
    start_utc_datetime: str = '',                         # ç™¼ä½ˆèµ·å§‹æ™‚é–“
    end_utc_datetime: str = '',                           # ç™¼ä½ˆæˆªæ­¢æ™‚é–“
    order: VideoSearchOrder = VideoSearchOrder.RELEVANCE, # æœå°‹æ’åº
    regionCode: Optional[RegionCode] = None,              # å½±ç‰‡åœ°å€ä»£ç¢¼
    relevanceLanguage: Optional[LanguageCode] = None,     # å½±ç‰‡èªè¨€ä»£ç¢¼
):
    service = get_youtube_service()
    videos: List[YoutubeVideo] = []
    result_status = StatusCode.WAIT_FOR_PROCESS
    result_message = ''
    next_page_token = None 
    current_page = 1 
    
    while True:
        try:
            # å»ºç«‹åŸºæœ¬åƒæ•¸å­—å…¸
            # youtube APIæœå°‹ä¸Šé™ç‚º50ç­†ï¼Œæ‰€ä»¥è®“maxResultsä¸è¶…é50
            search_params = {
                'part': 'snippet',
                'maxResults': min(search_count, 50),
                'order': order.value,
                'pageToken': next_page_token,
                'q': query,
                'type': 'video'
            }
            
            # æ ¹æ“šæ¢ä»¶å‹•æ…‹åŠ å…¥åƒæ•¸
            if start_utc_datetime:
                search_params['publishedAfter'] = start_utc_datetime
            if end_utc_datetime:
                search_params['publishedBefore'] = end_utc_datetime
            if regionCode:
                search_params['regionCode'] = regionCode.value
            if relevanceLanguage:
                search_params['relevanceLanguage'] = relevanceLanguage.value
            
            # ä½¿ç”¨å­—å…¸è§£æ§‹å‚³å…¥åƒæ•¸
            search_response = service.search().list(**search_params).execute()
        except HttpError as err:
            error_status = err.resp.status
            error_content = err.content.decode("utf-8") if hasattr(err.content, 'decode') else str(err.content)
            result_status = StatusCode.CALL_API_FAIL
            result_message = f'[final next_page_token:{next_page_token}] HTTP {error_status}, {error_content}'
            break
        except Exception as err:
            result_status = StatusCode.CALL_API_FAIL
            result_message = f'[final next_page_token:{next_page_token}] Unexpected error: {err}'
            break 
            
        new_videos = [
            YoutubeVideo(
                id=item['id']['videoId'],
                title=item['snippet']['title'],
                description=item['snippet']['description'],
                published_at=item['snippet']['publishedAt'],
                channel_title=item['snippet']['channelTitle'],
                channel_id=item['snippet']['channelId'],
                thumbnail_url=(
                    item.get('snippet', {})
                    .get('thumbnails', {})
                    .get('high', {})
                    .get('url')
                    or item.get('snippet', {})
                    .get('thumbnails', {})
                    .get('medium', {})
                    .get('url')
                    or item.get('snippet', {})
                    .get('thumbnails', {})
                    .get('default', {})
                    .get('url')
                )
            )
            for item in search_response.get('items', [])
            if item['id']['kind'] == 'youtube#video'
        ]
        videos.extend(new_videos)

        next_page_token = search_response.get('nextPageToken')
        search_count -= len(new_videos)
        if not next_page_token:
            result_status = StatusCode.SUCCESS
            break
        if search_count is not None and search_count <= 0:
            result_status = StatusCode.SUCCESS
            break      

    return BaseResponse[List[YoutubeVideo]](
        status_code = result_status,
        message=f'Successfully got {len(videos)} youtube videos' if result_status == StatusCode.SUCCESS else result_message,
        content = videos
    )

def fetch_videos_by_ids(video_ids: List[str]) -> BaseResponse[YoutubeVideo]:
    service = get_youtube_service()
    videos: List[YoutubeVideo] = []
    result_status = StatusCode.WAIT_FOR_PROCESS
    result_message = ''
    
    # å°‡å½±ç‰‡ ID åˆ—è¡¨åˆ†æ‰¹è™•ç†ï¼Œæ¯æ‰¹æ¬¡æœ€å¤š 50 å€‹, range(start, stop, step) 
    for i in range(0, len(video_ids), 50):
        # ç²å–ç•¶å‰æ‰¹æ¬¡çš„å½±ç‰‡ ID
        current_batch = video_ids[i:i + 50]
        
        # å°‡ ID åˆ—è¡¨è½‰æ›ç‚ºä»¥é€—è™Ÿåˆ†éš”çš„å­—ä¸²
        video_ids_string = ",".join(current_batch)
        
        # æª¢æŸ¥æ˜¯å¦é‚„æœ‰ ID éœ€è¦è™•ç†
        if not video_ids_string:
            break
            
        try:
            # å»ºç«‹åƒæ•¸å­—å…¸ï¼ŒåªåŒ…å«ç•¶å‰æ‰¹æ¬¡çš„ ID
            search_params = {
                'part': 'snippet,statistics',
                'id': video_ids_string,
                'maxResults': 50, 
            }
            
            # ä½¿ç”¨å­—å…¸è§£æ§‹å‚³å…¥åƒæ•¸
            search_response = service.videos().list(**search_params).execute()
        except HttpError as err:
            error_status = err.resp.status
            error_content = err.content.decode("utf-8") if hasattr(err.content, 'decode') else str(err.content)
            result_status = StatusCode.CALL_API_FAIL
            result_message = f'HTTP {error_status}, {error_content}'
            break
        except Exception as err:
            result_status = StatusCode.CALL_API_FAIL
            result_message = f'Unexpected error: {err}'
            break
            
        new_videos = [
            YoutubeVideo(
                id=item['id'],
                title=item['snippet']['title'],
                description=item['snippet']['description'],
                published_at=item['snippet']['publishedAt'],
                channel_title=item['snippet']['channelTitle'],
                channel_id=item['snippet']['channelId'],
                thumbnail_url=(
                    item.get('snippet', {})
                    .get('thumbnails', {})
                    .get('high', {})
                    .get('url')
                    or item.get('snippet', {})
                    .get('thumbnails', {})
                    .get('medium', {})
                    .get('url')
                    or item.get('snippet', {})
                    .get('thumbnails', {})
                    .get('default', {})
                    .get('url')
                ),
                viewCount=item['statistics'].get('viewCount', 0),
                likeCount=item['statistics'].get('likeCount', 0),
                dislikeCount=item['statistics'].get('dislikeCount', 0),
                commentCount=item['statistics'].get('commentCount', 0),
                is_enable_comment='commentCount' in item['statistics']
            )
            for item in search_response.get('items', [])
        ]
        videos.extend(new_videos)

    # è¿´åœˆçµæŸå¾Œï¼Œæª¢æŸ¥æ˜¯å¦æ‰€æœ‰å½±ç‰‡éƒ½å·²æˆåŠŸç²å–
    if not result_message:
        result_status = StatusCode.SUCCESS
    
    return BaseResponse[List[YoutubeVideo]](
        status_code=result_status,
        message=f'Successfully got {len(videos)} videos info by ids' if result_status == StatusCode.SUCCESS else result_message,
        content=videos
    )
    
def youtube_search_comments(
    video_id: str,                                 # è¦æŠ“å–ç•™è¨€çš„ YouTube å½±ç‰‡ ID
    max_comment_count_per_page: int = 100,         # é™åˆ¶æ¯é æŠ“å–ç•™è¨€æ•¸ä¸Šé™
    max_page: Optional[int] = None,                # é™åˆ¶æŠ“å–æœ€å¤§é æ•¸
    current_next_page_token: Optional[str] = None, # åƒ…åœ¨ "auto" æ¨¡å¼ä¸‹ä½¿ç”¨ï¼ŒçºŒæŠ“çš„èµ·å§‹ pageToken
    mode: str = "auto"                             # æ¨¡å¼: "full", "auto"
):
    service = get_youtube_service()
    comments: List[YoutubeComment] = []
    result_status = StatusCode.WAIT_FOR_PROCESS
    result_message = ''

    comment_index = 1
    # ä¾æ¨¡å¼æ±ºå®šèµ·å§‹ pageToken
    if mode == "auto":
        next_page_token = current_next_page_token
    else:
        next_page_token = None
    current_page = 1

    while True:
        try:
            response = service.commentThreads().list(
                part='snippet,replies',
                videoId=video_id,
                maxResults=max_comment_count_per_page,
                moderationStatus='published',
                order='relevance',  # relevance , time
                textFormat='plainText',
                pageToken=next_page_token
            ).execute()
            result_status = StatusCode.SUCCESS
        except HttpError as err:
            error_status = err.resp.status
            error_content = err.content.decode("utf-8") if hasattr(err.content, 'decode') else str(err.content)
            result_status = StatusCode.CALL_API_FAIL
            result_message = f'[final next_page_token:{next_page_token}][final video id:{video_id}] HTTP {error_status}, {error_content}'
            break
        except Exception as e:
            result_status = StatusCode.CALL_API_FAIL
            result_message = f'[final next_page_token:{next_page_token}][final video id:{video_id}] Unexpected error: {e}'
            break

        # è™•ç†ç•™è¨€èˆ‡å›è¦†
        for item in response.get('items', []):
            top_comment = item['snippet']['topLevelComment']['snippet']
            comments.append(YoutubeComment(
                id=comment_index,
                video_id = video_id,
                parent_id=None,
                level=1,
                textDisplay=top_comment['textDisplay'],
                likeCount=top_comment['likeCount'],
                published_at=top_comment['publishedAt'],
            ))
            comment_index += 1

            if 'replies' in item:
                top_comment_id = comment_index - 1
                for reply in item['replies']['comments']:
                    comments.append(YoutubeComment(
                        id=comment_index,
                        video_id = video_id,
                        parent_id=top_comment_id,
                        level=2,
                        textDisplay=reply['snippet']['textDisplay'],
                        likeCount=reply['snippet']['likeCount'],
                        published_at=reply['snippet']['publishedAt'],
                    ))
                    comment_index += 1

        # æ›´æ–°ä¸‹ä¸€é  token
        next_page_token = response.get('nextPageToken')

        # åœæ­¢æ¢ä»¶
        if not next_page_token:  # æ²’æœ‰ä¸‹ä¸€é 
            break
        if max_page is not None and current_page >= max_page:
            break

        current_page += 1

    return BaseResponse[YoutubeComment](
        status_code=result_status,
        message=f'Successfully got {len(comments)} youtube comments (include replies)' if result_status == StatusCode.SUCCESS else result_message,
        content=comments
    )

def fetch_video_cc_subtitle(video_id: str, languages: List[str], retry_count: int = 3) -> Optional[str]:
    """
    é€é YouTube å½±ç‰‡ ID å–å¾—å½±ç‰‡å…§å®¹ï¼Œä¸¦åŠ å…¥é‡è©¦æ©Ÿåˆ¶èˆ‡ä»£ç†ä¼ºæœå™¨æ”¯æ´ã€‚
    
    Args:
        video_id (str): YouTube å½±ç‰‡çš„ IDã€‚
        languages (List[str]): åå¥½çš„èªè¨€ä»£ç¢¼åˆ—è¡¨ã€‚
        retry_count (int): ç™¼ç”ŸéŒ¯èª¤æ™‚çš„é‡è©¦æ¬¡æ•¸ã€‚
    
    Returns:
        Optional[str]: å½±ç‰‡çš„æ–‡å­—å…§å®¹ï¼Œè‹¥ç„¡æ³•å–å¾—å‰‡è¿”å› Noneã€‚
    """
    transcript_text = ""

    print(f"å˜—è©¦å–å¾—å½±ç‰‡ ID: {video_id} çš„å®˜æ–¹å­—å¹•...")
    
    for attempt in range(retry_count):
        try:
            # å˜—è©¦å–å¾—CCå­—å¹•ï¼Œä¸¦å°‡ä»£ç†ä¼ºæœå™¨å‚³å…¥
            ytt_api = YouTubeTranscriptApi()
            transcript_list = ytt_api.fetch(
                video_id, 
                languages=languages
            )           
            # ä½¿ç”¨ .text å±¬æ€§ä¾†å­˜å–å­—å¹•å…§å®¹
            transcript_text = " ".join([snippet['text'] for snippet in transcript_list])
            print("âœ… æˆåŠŸå–å¾—å®˜æ–¹å­—å¹•ã€‚")
            return transcript_text

        except (TranscriptsDisabled, NoTranscriptFound) as e:
            print(f"æ‰¾ä¸åˆ°å½±ç‰‡ ID: {video_id} çš„å­—å¹•ï¼Œå›å‚³ç©ºç™½ã€‚")
            return ""
        
        except Exception as e:
            print(f"ç¬¬ {attempt + 1}/{retry_count} æ¬¡å˜—è©¦ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ï¼š{e}")
            
            if attempt < retry_count - 1:
                # å¦‚æœé‚„æœ‰é‡è©¦æ¬¡æ•¸ï¼Œå‰‡æš«åœä¸€æ®µæ™‚é–“å¾Œå†è©¦
                delay = 2 ** attempt  # é€™è£¡ä½¿ç”¨æŒ‡æ•¸é€€é¿ç­–ç•¥
                print(f"ç­‰å¾… {delay} ç§’å¾Œé‡è©¦...")
                time.sleep(delay)
            else:
                # æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—ï¼ŒçµæŸ
                print("æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—ã€‚")
                return None
    
    return None


def fetch_video_content(video_id: str, languages: list[str]) -> Optional[str]:
    """
    é€é YouTube å½±ç‰‡ ID å–å¾—å½±ç‰‡å…§å®¹ã€‚
    å„ªå…ˆå˜—è©¦å–å¾—å®˜æ–¹å­—å¹•ï¼Œè‹¥ç„¡å‰‡å°‡èªéŸ³è½‰æ–‡å­—ã€‚
    
    Args:
        video_id (str): YouTube å½±ç‰‡çš„ IDã€‚
        languages (list[str]): åå¥½çš„èªè¨€ä»£ç¢¼åˆ—è¡¨ã€‚
    
    Returns:
        Optional[str]: å½±ç‰‡çš„æ–‡å­—å…§å®¹ï¼Œè‹¥ç„¡æ³•å–å¾—å‰‡è¿”å› Noneã€‚
    """
    transcript_text = ""

    print(f"å˜—è©¦å–å¾—å½±ç‰‡ ID: {video_id} çš„å®˜æ–¹å­—å¹•...")
    try:
        # å„ªå…ˆå˜—è©¦å–å¾—CCå­—å¹•
        ytt_api = YouTubeTranscriptApi()
        transcript_list = ytt_api.fetch(
            video_id, 
            languages=languages
        )
        
        # å°‡å­—å¹•ç‰‡æ®µåˆä½µæˆä¸€å€‹å®Œæ•´çš„å­—ä¸²
        transcript_text = " ".join([snippet['text'] for snippet in transcript_list])
        print("âœ… æˆåŠŸå–å¾—å®˜æ–¹å­—å¹•ã€‚")
        return transcript_text

    except (TranscriptsDisabled, NoTranscriptFound) as e:
        print(f"å½±ç‰‡æ²’æœ‰å®˜æ–¹å­—å¹•")
        print("è½‰ç‚ºä½¿ç”¨èªéŸ³è½‰æ–‡å­—...")

        # æ ¹æ“š download_path å»ºç«‹éŸ³é »æª”æ¡ˆè·¯å¾‘
        download_dir = "./data/audio"
        os.makedirs(os.path.dirname(download_dir), exist_ok=True)
        output_template = os.path.join(download_dir, video_id)
        audio_file_path = f'{output_template}.mp3'

        if not os.path.exists(audio_file_path):
            # ä½¿ç”¨ yt-dlp ä¸‹è¼‰éŸ³é »
            ydl_opts = {
                'format': 'bestaudio/best',
                'outtmpl': output_template,
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': 'mp3',
                    'preferredquality': '192',
                }],
                'quiet': True,
                'noprogress': True,
            }
    
            try:
                print(f"ğŸ§ é–‹å§‹ä¸‹è¼‰å½±ç‰‡éŸ³è»Œè‡³ï¼š{audio_file_path}")
                with YoutubeDL(ydl_opts) as ydl:
                    ydl.download([f"https://www.youtube.com/watch?v={video_id}"])
            except Exception as e:
                print(f"ä¸‹è¼‰éŸ³è»Œå¤±æ•—ï¼š{e}")
                return None

        transcribed_text = None
        # ç¢ºä¿æª”æ¡ˆå­˜åœ¨ï¼Œå¦å‰‡è½‰éŒ„æœƒå¤±æ•—
        if not os.path.exists(audio_file_path):
            print("éŸ³è»Œæª”æ¡ˆä¸å­˜åœ¨ï¼Œç„¡æ³•é€²è¡Œè½‰éŒ„ã€‚")
            return None
        
        try:
            print("ğŸ”Š ä¸‹è¼‰å®Œæˆï¼Œé–‹å§‹èªéŸ³è½‰æ–‡å­—...")
            
            # è¼‰å…¥ Faster-Whisper æ¨¡å‹ï¼Œå¯ä¾éœ€æ±‚èª¿æ•´æ¨¡å‹å¤§å°
            model_size = "base"
            model = WhisperModel(model_size, device="cpu", compute_type="int8")

            # è½‰éŒ„éŸ³é »
            segments, info = model.transcribe(audio_file_path, beam_size=5)
            
            transcribed_text = " ".join([segment.text for segment in segments])
            print("âœ… èªéŸ³è½‰æ–‡å­—å®Œæˆã€‚")
            
        except Exception as e:
            print(f"ç™¼ç”ŸèªéŸ³è½‰æ–‡å­—éŒ¯èª¤ï¼š{e}")
        finally:
            # ç„¡è«–æˆåŠŸèˆ‡å¦ï¼Œéƒ½åˆªé™¤éŸ³é »æª”æ¡ˆ
            if os.path.exists(audio_file_path):
                print(f"ğŸ—‘ï¸ æ­£åœ¨åˆªé™¤éŸ³é »æª”æ¡ˆï¼š{audio_file_path}")
                os.remove(audio_file_path)
                print("âœ… æª”æ¡ˆåˆªé™¤æˆåŠŸã€‚")
            
        return transcribed_text

    except Exception as e:
        print(f"ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ï¼š{e}")
        return None